---
---

搞不清这个应该算第几次实验了，好像不是11，麻烦助教改一下，抱歉。

---

从测试程序`testPipeline.cpp`入手，先跑一下看看：
![image.png](https://s2.loli.net/2023/06/05/PeM7vKECzA684Tu.png)

```cpp
pr::PipelinePR prc(...);
// 加载已训练的模型文件到pipeline
cv::Mat img = cv::imread("res/test.jpg");
// 加载图片
std::vector<pr::PlateInfo> res = prc.RunPiplineAsImage(img,0);
// 使用pipeline处理图片，将识别到的每个车牌的信息存入vector
// 车牌信息对象的格式为PlateInfo
for (auto st : res) {
  // 遍历识别到的每个车牌
  if (st.confidence > 0.75) {
    std::cout << st.getPlateName() << " " << st.confidence << 
    std::endl;

    // 输出各个车牌的牌号和confidence
  
    cv::Rect region = st.getPlateRect();
    // 读取PlateInfo中车牌所在的矩形区域
    cv::rectangle(
	    img, cv::Point(region.x, region.y),
	    cv::Point(region.x + region.width, region.y + region.height), 
	    cv::Scalar(255, 255, 0), 2);
    // 将矩形画在原图片上，以供最后显示
  }
}
cv::imshow("image", img);
cv::waitKey(0);
// 显示图片，带刚才画的矩形
```

所以程序的核心在于`prc.RunPiplineAsImage`，它接收一个图片，返回图片中识别到的车牌信息。

```cpp
std::vector<PlateInfo> PipelinePR::RunPiplineAsImage(cv::Mat plateimg,int IsDB)
{
	std::vector<pr::PlateInfo> plates;
	std::vector<PlateInfo> plateres;
	if(IsDB==1){
		// ...
	}
	else{
		platedetection->Detectssd(plateimg, plates);
	}
	
	for (pr::PlateInfo plateinfo : plates) {
		cv::Mat image = plateinfo.getPlateImage();
		cv::Mat CropImg;
		
		if(IsDB==1){
			// ...
		}
		else{
			finetune->Finetune(image, CropImg);
			platerecognation->segmentation_free_recognation(
				CropImg, plateinfo
			);
		}
		plateres.push_back(plateinfo);
	}
	
	return plateres;
}
```
测试程序的`IsDB`参数为`0`，那就先只关注它为`0`时需要执行的函数，下面按顺序逐个看。
```cpp
void PlateDetection::Detectssd(cv::Mat img, std::vector<pr::PlateInfo> &plateInfos){

	int cols = img.cols;
	int rows = img.rows;
	Mat in;
	img.convertTo(in, CV_32F);
	Mat input(img.size(), CV_32FC3);
	Mat inputblob1 = input.reshape(1, { 1, 3,rows,cols });
	Mat input_blob = dnn::blobFromImages(
		in, 0.225, Size(),
		Scalar(103.53, 116.28, 123.675), false
	);
	float *blobdata = input_blob.ptr<float>();
	float *blobdata2 = inputblob1.ptr<float>();
	
	for (int i = 0; i < rows; i++){
		memcpy(
			blobdata2 + i * cols,
			blobdata + 3 * i * cols,
			cols * sizeof(float)
		);
		memcpy(
			blobdata2 + i * cols + rows * cols,
			blobdata + (1 + 3 * i) * cols,
			cols * sizeof(float)
		);
		memcpy(
			blobdata2 + i * cols + rows * cols * 2,
			blobdata + (2 + 3 * i) * cols,
			cols * sizeof(float)
		);
	}

	// 以上都是原图->神经网络输入数据的预处理

	// 输入SSD检测网络，前向传播得到结果矩阵
	ssdNet.setInput(inputblob1);
	Mat outputBlob = ssdNet.forward("detection_out");
	Mat detectmat(
		outputBlob.size[2], outputBlob.size[3], 
		CV_32F, outputBlob.ptr<float>()
	);

	// 神经网络的输出detectmat有7行
	// 每行表示一块可能为车牌的区域的信息
	// 前2行固定为0和1，后面5行分别表示：
	// 这块区域是车牌的概率（信心）
	// 以及区域的左上和右下两个点的四个归一化坐标

	vector<Rect> recs;
	vector<float>scs;
	
	for (int i = 0; i < detectmat.rows; i++){
	
		float confidence = detectmat.at<float>(i, 2);
		// 这里根据detectmat每一行的车牌信息
		// 将图片的对应矩形区域切出来一个子图
		// 存入platInfo中返回
		if (confidence > 0.5){
			int x1, x2, y1, y2;
			Rect rec;
			Mat cimg;
			// 由于坐标是归一化的，需要乘上图片尺寸还原
			x1 = int(detectmat.at<float>(i, 3) * cols);
			y1 = int(detectmat.at<float>(i, 4) * rows);
			x2 = int(detectmat.at<float>(i, 5) * cols);
			y2 = int(detectmat.at<float>(i, 6) * rows);
			x1 = max(x1, 0);
			y1 = max(y1, 0);
			x2 = min(x2, cols - 1);
			y2 = min(y2, rows - 1);
			rec.x = x1;
			rec.y = y1;
			rec.width = (x2 - x1 + 1);
			rec.height = (y2 - y1 + 1);
			img(rec).copyTo(cimg);
			PlateInfo plateInfo(cimg, rec);
			plateInfos.push_back(plateInfo);
		}
	
	}

}
```

那blob是什么呢：

>在计算机视觉中，blob指的是二进制大对象（Binary Large OBject），也称为二进制数据块。它是一种将图像或视频等多维数据存储为单一二进制文件的方法。
>在OpenCV中，blob通常是由一组连通的像素组成的区域。可以使用一些函数对这些blob进行操作，例如提取其边界框、计算其面积和重心等。blob在目标检测、图像分割和跟踪等计算机视觉任务中有着广泛的应用。

总之就是一种适合输入给神经网络的一块二进制数据，大概相当于把图片的每个通道拉直了怼在一起，只包含关键信息——图片每个像素的值，那三个memcpy就是在做这个，对应RGB三个通道。反正神经网络的输入格式都是自己定的，那肯定怎么方便怎么来。

接下来是`FineTune`微调函数，先看看输入输出是啥：
![image.png](https://s2.loli.net/2023/06/05/McFeS2GEm1twk9Q.png)

看起来这个函数能把车牌摆正，有利于下一步文字识别。
```cpp
void FineTune::Finetune(Mat src, Mat& dst){
	Mat tof;// = src.clone();
	resize(src, tof, Size(120, 48));
	Mat blob = dnn::blobFromImage(
		tof, 0.0078125, 
		Size(120, 48), Scalar(127.5, 127.5, 127.5), 
		false, false
	);
	
	FTNet.setInput(blob);
	Mat outblob = FTNet.forward("conv6-3");
	
	float *data = outblob.ptr<float>();
	vector<Point> pts(4);
	Mat fineMat(Size(2, 4), CV_32F, data);

	// 上面的过程跟之前一样，
	// 转换为blob输入给神经网络，得到输出，转换回mat

	// fineMat有四行四个点，八个归一化坐标
	
	for (int i = 0; i < fineMat.rows; i++){
		pts[i].x = fineMat.at<float>(i, 0)*src.cols;
		pts[i].y = fineMat.at<float>(i, 1)*src.rows;
	}
		
	Mat crop;
	// 根据八个坐标对车牌区域图像进行进行refine
	to_refine(src, pts, crop);
	
	blob = dnn::blobFromImage(
		crop, 0.0078128, 
		Size(120, 48), Scalar(127.5, 127.5, 127.5), 
		false, false
	);
	FTNet.setInput(blob);
	outblob = FTNet.forward("conv6-3");

	// refine后的图像输入到第二个网络进一步处理
	// 输出也是四行八个归一化坐标

	data = outblob.ptr<float>();
	Mat fineMat2(Size(2, 4), CV_32F, data);
	
	for (int i = 0; i < fineMat.rows; i++){
		pts[i].x = fineMat2.at<float>(i, 0)*crop.cols;
		pts[i].y = fineMat2.at<float>(i, 1)*crop.rows;
	}

	// 根据归一化坐标进行affine
	affine_crop(crop, pts, crop);
	dst = crop.clone();
	
}

```
这里用了两个神经网络，先后做了refine和affine，过程是这样的：
![image.png](https://s2.loli.net/2023/06/05/Itd1wDA9vgHlZSf.png)
![image.png](https://s2.loli.net/2023/06/05/BUOcIvCljxKnQST.png)
![image.png](https://s2.loli.net/2023/06/05/McFeS2GEm1twk9Q.png)

refine和affine的具体代码就不看了，已经是CV技术细节了，也看不太懂。

接下来是文字识别：
```cpp
void PlateRecognation::segmentation_free_recognation(cv::Mat src, pr::PlateInfo &plateinfo){

	float score = 0;	
	string text = "";	
	Mat src1 = src.clone();	
	Mat inputMat(Size(40, 160), CV_8UC3);
	
	  
	
	for (int j = 0; j < src.rows; j++){
		for (int i = 0; i < src.cols; i++){		
			inputMat.at<Vec3b>(i, j) = src1.at<Vec3b>(j, i);		
		}
	}
	
	Mat blob = dnn::blobFromImage(
		inputMat, 1 / 255.f,
		Size(40, 160), Scalar(0, 0, 0),
		false, false
	);
	
	RecNet.setInput(blob);
	Mat outblob = RecNet.forward();
	
	int x = outblob.size[2];	
	int y = outblob.size[0];	
	float *data = outblob.ptr<float>();	

	// 还是神经网络，输出到这个data
	// data应该是一个长度为20*84的数组
	// 其中84为车牌字符集长度
	// 20大概是车牌字符数上限？（有这么多吗
	
	vector<float> scores(84);	
	vector<int>maxidxs;
	vector<float> maxscore;
	
	for (int i = 2; i < 20; i++){
		// i表示正在读取车牌上第i个字符的信息
		// 每个字符的读取用的是同一个scores
		for (int j = 0; j < 84; j++){
			scores[j] = data[j * 20 + i];
			// scores[j]为当前字符是字符集中第j个字符的概率（信心）
		}		
		int idx = max_element(scores.begin(), scores.end())
		 - scores.begin();		
		maxidxs.push_back(idx);
		maxscore.push_back(scores[idx]);
		// 记录当前字符最可能是哪个字符，以及对应的概率（信心）
	}
	
	int charnum = 0;
	for (int i = 0; i < maxidxs.size(); i++){
		if (maxidxs[i] < pr::CH_PLATE_CODE.size()
		&& (i == 0 || (maxidxs[i - 1] != maxidxs[i]))){
			text += pr::CH_PLATE_CODE[maxidxs[i]];
			// 根据每个index生成车牌字符串
			score += maxscore[i];
			// 累加每个字符的score，后面有用
			charnum++;
		}
	}
	
	if (charnum > 0){
		// 车牌的整体识别信心为每个字符的信心的平均值
		score /= charnum;
	}
	
	plateinfo.setPlateName(text);
	plateinfo.confidence = score;
}
```
其中这一段有点意思：
```cpp
	for (int i = 0; i < maxidxs.size(); i++){
		if (maxidxs[i] < pr::CH_PLATE_CODE.size()
		&& (i == 0 || (maxidxs[i - 1] != maxidxs[i]))){
			text += pr::CH_PLATE_CODE[maxidxs[i]];
			// 根据每个index生成车牌字符串
			score += maxscore[i];
			// 累加每个字符的score，后面有用
			charnum++;
		}
	}
```
那我猜，这个神经网络的输出虽然是20个字符块 $\times$ 84个可能的字符index，但是并不太稳定：同一个字符块很可能被重复识别多次，也可能在这20个单元里并不是连续分布的，比如分布在第`2,5,10,13,14,19`行，唯一可以确定的是字符顺序不会乱，所以这一段才要写这么多清洗逻辑。

---
根据上面用到`PlateInfo`的场景，这个类应该储存了以下信息：
- 车牌字符串
- 车牌识别的confidence
- 识别到车牌的区域的子图
一开始每个对象只存了子图，之后每一步都在往对象里填新的东西。